{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8f9948",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb106354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85912f9f",
   "metadata": {},
   "source": [
    "# Send And Receive Func for Huge Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92c5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receive data until fully received (For Huge data => chunk by chunk)\n",
    "def receive_data(socket, length):\n",
    "    data = b''\n",
    "    while len(data) < length:\n",
    "        packet = socket.recv(length - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data\n",
    "\n",
    "# Send data in chunks(For Huge data => chunk by chunk)\n",
    "def send_data(socket, data):\n",
    "    data_pickle = pickle.dumps(data)\n",
    "    data_size = len(data_pickle)\n",
    "    socket.sendall(data_size.to_bytes(4, 'big'))  # Send data size first\n",
    "\n",
    "    sent = 0\n",
    "    while sent < data_size:\n",
    "        chunk = data_pickle[sent:sent+4096]  # Send in chunks\n",
    "        socket.sendall(chunk)\n",
    "        sent += len(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f331a",
   "metadata": {},
   "source": [
    "#  Initialize server socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb55c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server_address = ('localhost', 1111)\n",
    "server_socket.bind(server_address)\n",
    "server_socket.listen(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ca565",
   "metadata": {},
   "source": [
    "# Set Federated Learning Server Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e5ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of server_rounds or aggregation local models\n",
    "server_rounds = 10   \n",
    "\n",
    "client_num = 4\n",
    "clients = []\n",
    "client_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ef2d0",
   "metadata": {},
   "source": [
    "# Define Local Models Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fdc9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 784\n",
    "n0 = num_features\n",
    "n1 = 20\n",
    "n2 = 15\n",
    "n3 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca431b",
   "metadata": {},
   "source": [
    "# Initialize Client Local Models Paramters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b299d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "np.random.seed(1)\n",
    "a = -1\n",
    "b = 1\n",
    "w1 = np.random.uniform(a, b, size=(n1, n0))\n",
    "w2 = np.random.uniform(a, b, size=(n2, n1))\n",
    "w3 = np.random.uniform(a, b, size=(n3, n2))\n",
    "\n",
    "# Initialize biases\n",
    "b1 = np.random.uniform(a, b, size=(n1, 1))\n",
    "b2 = np.random.uniform(a, b, size=(n2, 1))\n",
    "b3 = np.random.uniform(a, b, size=(n3, 1))\n",
    "\n",
    "\n",
    "initial_parameters = {'weights': [w1, w2, w3], 'bias': [b1, b2, b3], 'server_rounds':server_rounds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b64d5fa",
   "metadata": {},
   "source": [
    "# Config For Save Train And Test Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24311896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame to store\n",
    "train_results_columns = ['Round', 'Client_ID', 'First_Layer_Weights', 'Second_Layer_Weights','Third_Layer_Weights', 'First_Layer_Bias', 'Second_Layer_Bias', 'Third_Layer_Bias','Train_MSE','Train_Accuracy']\n",
    "train_results = pd.DataFrame(columns=train_results_columns)\n",
    "\n",
    "server_model_columns= ['Round', 'First_Layer_Weights', 'Second_Layer_Weights','Third_Layer_Weights', 'First_Layer_Bias', 'Second_Layer_Bias', 'Third_Layer_Bias']\n",
    "server_model = pd.DataFrame(columns=server_model_columns)\n",
    "\n",
    "test_results_columns= ['Round', 'Client_ID','Test_MSE','Test_Accuracy']\n",
    "test_results = pd.DataFrame(columns=test_results_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ff644",
   "metadata": {},
   "source": [
    "# Federated Learning Process Handling On Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "680aac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************************************************\n",
      "*********************************** WATTING FOR CONNECTIONS **************************************\n",
      "**************************************************************************************************\n",
      "Connection from ('127.0.0.1', 14417)\n",
      "Connection from ('127.0.0.1', 14418)\n",
      "Connection from ('127.0.0.1', 14428)\n",
      "Connection from ('127.0.0.1', 14461)\n",
      "Sent Initial Params To All Clients\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 1\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 1\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 2\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 2\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 3\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 3\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 4\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 4\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 5\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 5\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 6\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 6\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 7\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 7\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 8\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 8\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 9\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 9\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "Start Round 10\n",
      "Pending Receive Params From Clients For Next Round\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "Start Aggregation Process\n",
      "End Aggregation Process\n",
      "Sent Aggregated Model Params To Client To Evaluate On Test Data\n",
      "Pending Receive Test results From Clients\n",
      "Received From ClientID:  C1\n",
      "Received From ClientID:  C3\n",
      "Received From ClientID:  C2\n",
      "Received From ClientID:  C4\n",
      "End Round 10\n",
      "\n",
      "\u001b[1;m*****************************************************************************************************************************\n",
      "**************************************************************************************************\n",
      "******************************************* FL END ***********************************************\n",
      "**************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print('**************************************************************************************************')\n",
    "print('*********************************** WATTING FOR CONNECTIONS **************************************')\n",
    "print('**************************************************************************************************')\n",
    "\n",
    "while len(clients) < client_num: \n",
    "    client, client_address = server_socket.accept()\n",
    "    clients.append(client)\n",
    "    print(f\"Connection from {client_address}\")\n",
    "    \n",
    "    # Send initial params for current iteration to the clients\n",
    "    send_data(client, initial_parameters)\n",
    "    \n",
    "print(\"Sent Initial Params To All Clients\")\n",
    "\n",
    "print(\"\\n\\033[1;m\" + \"*\" * 125)\n",
    "\n",
    "current_round = 0 \n",
    "while current_round < server_rounds:\n",
    "    # Send ready signal to clients\n",
    "    for client in clients:\n",
    "        client.send(pickle.dumps({'ready': True}))\n",
    "    \n",
    "    print(\"Start Round\",current_round+1)\n",
    "    ############################################################\n",
    "    #  Wait For Local Model Train Results\n",
    "    ############################################################\n",
    "    # Receive updated train params from clients for the next round\n",
    "    client_train_res = {}\n",
    "    print('Pending Receive Params From Clients For Next Round')\n",
    "    \n",
    "    for client in clients:\n",
    "        data_size = int.from_bytes(client.recv(4), 'big')  # Receive data size first\n",
    "        data = receive_data(client, data_size) \n",
    "        client_train_res[client.getpeername()] = pickle.loads(data)\n",
    "        print('Received From ClientID: ',client_train_res[client.getpeername()][\"client_id\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################################\n",
    "    #  Aggregate weights based on the number of samples\n",
    "    ############################################################\n",
    "    \n",
    "    print(\"Start Aggregation Process\")\n",
    "    total_samples = sum(client_train_res[addr]['num_samples'] for addr in client_train_res)\n",
    "    # Calculate weighted average of params from clients\n",
    "    aggregated_parameters = {\n",
    "        'weights': [np.zeros_like(w1), np.zeros_like(w2), np.zeros_like(w3)],\n",
    "        'bias': [np.zeros_like(b1), np.zeros_like(b2), np.zeros_like(b3)],\n",
    "        'current_server_round':current_round\n",
    "        }\n",
    "    \n",
    "    for addr, client_train_data in client_train_res.items():\n",
    "        ratio = client_train_data['num_samples'] / total_samples \n",
    "        for i in range(len(aggregated_parameters['weights'])): \n",
    "            aggregated_parameters['weights'][i] += client_train_data['weights'][i] * ratio\n",
    "            aggregated_parameters['bias'][i] += client_train_data['bias'][i] * ratio\n",
    "    \n",
    "    print(\"End Aggregation Process\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################################\n",
    "    #  Send updated model to clients for evaluate by test data\n",
    "    ############################################################\n",
    "    for client in clients:\n",
    "        send_data(client, aggregated_parameters)\n",
    "    print(\"Sent Aggregated Model Params To Client To Evaluate On Test Data\")   \n",
    "    \n",
    "    print('Pending Receive Test results From Clients')\n",
    "    # Receive evaluate global model on test-result from clients \n",
    "    client_test_res = {}\n",
    "    for client in clients: \n",
    "        data_size = int.from_bytes(client.recv(4), 'big')  # Receive data size first\n",
    "        data = receive_data(client, data_size)\n",
    "        client_test_res[client.getpeername()] = pickle.loads(data)\n",
    "        print('Received From ClientID: ',client_test_res[client.getpeername()][\"client_id\"])\n",
    "    \n",
    "    \n",
    "    # Save train results for each client in each round on a excel file\n",
    "    for addr, client_train_data in client_train_res.items(): \n",
    "        # Convert weights matrices to JSON format\n",
    "        first_layer_weights_json = json.dumps({f\"w{row+1}_{col+1}\": client_train_data['weights'][0][row][col]\n",
    "                                              for row in range(client_train_data['weights'][0].shape[0])\n",
    "                                              for col in range(client_train_data['weights'][0].shape[1])})\n",
    "        \n",
    "        second_layer_weights_json = json.dumps({f\"w{row+1}_{col+1}\": client_train_data['weights'][1][row][col]\n",
    "                                               for row in range(client_train_data['weights'][1].shape[0])\n",
    "                                               for col in range(client_train_data['weights'][1].shape[1])})\n",
    "        \n",
    "        third_layer_weights_json = json.dumps({f\"w{row+1}_{col+1}\": client_train_data['weights'][2][row][col]\n",
    "                                              for row in range(client_train_data['weights'][2].shape[0])\n",
    "                                              for col in range(client_train_data['weights'][2].shape[1])})\n",
    "        \n",
    "        first_layer_bias_json = json.dumps({f\"b{row+1}_{col+1}\": client_train_data['bias'][0][row][col]\n",
    "                                              for row in range(client_train_data['bias'][0].shape[0])\n",
    "                                              for col in range(client_train_data['bias'][0].shape[1])})\n",
    "        \n",
    "        second_layer_bias_json = json.dumps({f\"b{row+1}_{col+1}\": client_train_data['bias'][1][row][col]\n",
    "                                               for row in range(client_train_data['bias'][1].shape[0])\n",
    "                                               for col in range(client_train_data['bias'][1].shape[1])})\n",
    "        \n",
    "        third_layer_bias_json = json.dumps({f\"b{row+1}_{col+1}\": client_train_data['bias'][2][row][col]\n",
    "                                              for row in range(client_train_data['bias'][2].shape[0])\n",
    "                                              for col in range(client_train_data['bias'][2].shape[1])})\n",
    "\n",
    "        train_results = train_results.append({\n",
    "            'Round': current_round + 1,\n",
    "            'Client_ID': client_train_data[\"client_id\"],\n",
    "            'First_Layer_Weights': first_layer_weights_json,\n",
    "            'Second_Layer_Weights': second_layer_weights_json,\n",
    "            'Third_Layer_Weights': third_layer_weights_json,\n",
    "            'First_Layer_Bias': first_layer_bias_json,\n",
    "            'Second_Layer_Bias': second_layer_bias_json,\n",
    "            'Third_Layer_Bias': third_layer_bias_json,\n",
    "            'Train_MSE': client_train_data[\"Train_MSE\"],\n",
    "            'Train_Accuracy': client_train_data[\"Train_Accuracy\"]*100\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "         \n",
    "    # save aggregated model params\n",
    "    # Convert aggregated matrices to JSON format\n",
    "    first_layer_weights_json = json.dumps({f\"w{row+1}_{col+1}\": aggregated_parameters['weights'][0][row][col]\n",
    "                                            for row in range(aggregated_parameters['weights'][0].shape[0])\n",
    "                                            for col in range(aggregated_parameters['weights'][0].shape[1])})\n",
    "        \n",
    "    second_layer_weights_json = json.dumps({f\"w{row+1}_{col+1}\": aggregated_parameters['weights'][1][row][col]\n",
    "                                            for row in range(aggregated_parameters['weights'][1].shape[0])\n",
    "                                            for col in range(aggregated_parameters['weights'][1].shape[1])})\n",
    "        \n",
    "    third_layer_weights_json = json.dumps({f\"w{row+1}_{col+1}\": aggregated_parameters['weights'][2][row][col]\n",
    "                                            for row in range(aggregated_parameters['weights'][2].shape[0])\n",
    "                                            for col in range(aggregated_parameters['weights'][2].shape[1])})\n",
    "        \n",
    "    first_layer_bias_json = json.dumps({f\"b{row+1}_{col+1}\": aggregated_parameters['bias'][0][row][col]\n",
    "                                            for row in range(aggregated_parameters['bias'][0].shape[0])\n",
    "                                            for col in range(aggregated_parameters['bias'][0].shape[1])})\n",
    "        \n",
    "    second_layer_bias_json = json.dumps({f\"b{row+1}_{col+1}\": aggregated_parameters['bias'][1][row][col]\n",
    "                                            for row in range(aggregated_parameters['bias'][1].shape[0])\n",
    "                                            for col in range(aggregated_parameters['bias'][1].shape[1])})\n",
    "        \n",
    "    third_layer_bias_json = json.dumps({f\"b{row+1}_{col+1}\": aggregated_parameters['bias'][2][row][col]\n",
    "                                            for row in range(aggregated_parameters['bias'][2].shape[0])\n",
    "                                            for col in range(aggregated_parameters['bias'][2].shape[1])})\n",
    "        \n",
    "    server_model = server_model.append({\n",
    "            'Round': current_round + 1,\n",
    "            'First_Layer_Weights': first_layer_weights_json,\n",
    "            'Second_Layer_Weights': second_layer_weights_json,\n",
    "            'Third_Layer_Weights': third_layer_weights_json,\n",
    "            'First_Layer_Bias': first_layer_bias_json,\n",
    "            'Second_Layer_Bias': second_layer_bias_json,\n",
    "            'Third_Layer_Bias': third_layer_bias_json\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Save test results for each client\n",
    "    for addr, client_test_data in client_test_res.items(): \n",
    "        \n",
    "        test_results = test_results.append({ \n",
    "            'Round': current_round + 1,\n",
    "            'Client_ID': client_test_data[\"client_id\"], \n",
    "            'Test_MSE': client_test_data[\"Test_MSE\"],\n",
    "            'Test_Accuracy':client_test_data[\"Test_Accuracy\"]*100\n",
    "        }, ignore_index=True)\n",
    "  \n",
    "\n",
    "    print(\"End Round\",current_round+1)\n",
    "    print(\"\\n\\033[1;m\" + \"*\" * 125)\n",
    "    \n",
    "    current_round += 1\n",
    "    \n",
    "# Send termination signal to clients\n",
    "for client in clients:\n",
    "    client.send(pickle.dumps({'terminate': True}))\n",
    "\n",
    "# Export DataFrames to Excel file\n",
    "train_results.to_excel('train_results.xlsx', index=False) \n",
    "server_model.to_excel('server_model.xlsx', index=False)\n",
    "test_results.to_excel('test_results.xlsx', index=False)\n",
    "\n",
    "# Close connections\n",
    "server_socket.close()\n",
    "\n",
    "print('**************************************************************************************************')\n",
    "print('******************************************* FL END ***********************************************')\n",
    "print('**************************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cb3c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_model.to_excel('server_model.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9b369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
