{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Excel file\n",
    "data = pd.read_excel('Lorenz Dataset.xlsx', header=None).values  \n",
    "# data = pd.read_excel('Tehran Stock Exchange.xlsx', header=None).values\n",
    "\n",
    "data_size = len(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the input data\n",
    "for ii in range(len(data[0])): \n",
    "    data[:, ii] = data[:, ii] / np.max(data[:, ii])  \n",
    "\n",
    "num_feature = len(data[0]) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    for elem in row:\n",
    "        if abs(elem) > 1:\n",
    "            print(row, elem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lorenz Dataset\n",
    "# np.random.seed(42)\n",
    "# epochs = 100 \n",
    "# regularization_strength = 0.003\n",
    "# learning_rate = 0.001 \n",
    "\n",
    "#Stock Dataset\n",
    "np.random.seed(41)\n",
    "epochs = 100 \n",
    "regularization_strength = 0.008\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMDHNeuron:\n",
    "    def __init__(self, x1_index, x2_index):\n",
    "        self.x1_index = x1_index\n",
    "        self.x2_index = x2_index\n",
    "        self.weights = np.random.uniform(-1, 1, 6) \n",
    "        self.train_mse_history = []\n",
    "        self.validation_mse = None\n",
    "        \n",
    "    def train(self, x1_train, x2_train, actual_output, epochs,learning_rate, regularization_strength):\n",
    "        self.train_mse_history = []\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(x1_train)):\n",
    "                predicted_output = self.predict(x1_train[i], x2_train[i])\n",
    "                error = predicted_output - actual_output[i]\n",
    "#                 print('index: ', i)\n",
    "#                 print('error: ', error)\n",
    "#                 print('x1_train[i]**2: ',x1_train[i]**2)\n",
    "#                 print('x2_train[i]**2: ',x2_train[i]**2)\n",
    "                \n",
    "                gradient = np.array([\n",
    "                    -1 * error * x1_train[i]**2,\n",
    "                    -1 * error * x2_train[i]**2,\n",
    "                    -1 * error * x1_train[i] * x2_train[i],\n",
    "                    -1 * error * x1_train[i],\n",
    "                    -1 * error * x2_train[i],\n",
    "                    -1 * error\n",
    "                ])\n",
    "                \n",
    "                # L2 regularization\n",
    "                regularization_term = 2 * regularization_strength * self.weights  \n",
    "                \n",
    "                self.weights = self.weights - learning_rate * gradient - regularization_term\n",
    "            \n",
    "            train_mse = self.calculate_mse(x1_train, x2_train, actual_output)\n",
    "#             print(train_mse)\n",
    "            self.train_mse_history.append(train_mse)\n",
    "        \n",
    "        # calculate validation MSE\n",
    "        self.validation_mse = self.calculate_mse(validation_data[:,self.x1_index],validation_data[:,self.x2_index],validation_output)\n",
    "        \n",
    "    def predict(self, x1, x2):\n",
    "        return self.weights[0] * x1**2 + self.weights[1] * x2**2 + self.weights[2] * x1 * x2 + self.weights[3] * x1  + self.weights[4] * x2 + self.weights[5]\n",
    "\n",
    "    def calculate_mse(self, x1, x2, target):\n",
    "        predicted_output = self.predict(x1, x2)\n",
    "        mse = np.mean((predicted_output - target) ** 2)\n",
    "        return mse\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and testing sets\n",
    "train_size = int(0.7 * data_size)\n",
    "validation_size = int(0.15 * data_size)\n",
    "\n",
    "train_data, validation_data, test_data = data[:train_size,:num_feature], data[train_size:train_size + validation_size,:num_feature], data[train_size + validation_size:,:num_feature]\n",
    "train_output, validation_output, test_output = data[:train_size,num_feature], data[train_size:train_size + validation_size,num_feature], data[train_size + validation_size:,num_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmdh_neurons = []\n",
    "for i in range(num_feature):\n",
    "    for j in range(i + 1, num_feature):\n",
    "        neuron = GMDHNeuron(i,j)\n",
    "        neuron.train(train_data[:, i], train_data[:, j], train_output, epochs,learning_rate, regularization_strength)\n",
    "        gmdh_neurons.append(neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron in gmdh_neurons:\n",
    "    # Plotting the training data and output\n",
    "    plt.figure(figsize=(20, 8)) \n",
    "    plt.semilogy(np.arange(1, epochs + 1 ), neuron.train_mse_history)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Train') \n",
    "    plt.show()\n",
    "    print('selected_neurons-indexs: ', neuron.x1_index,neuron.x2_index)\n",
    "    print(\"Final Weights:\", neuron.weights)\n",
    "    print(\"Final Train MSE:\", neuron.train_mse_history[-1])\n",
    "    print(\"Final Validation MSE:\", neuron.validation_mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_neurons = sorted(gmdh_neurons, key=lambda x: x.validation_mse)\n",
    "# Select the top two neurons with the lowest validation_mse\n",
    "best_neurons = sorted_neurons[:2]\n",
    "print(\"Two smallest validation MSE values:\", best_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_neurons_output = []\n",
    "for neuron in best_neurons:  \n",
    "    print('indexes: ', neuron.x1_index,neuron.x2_index)\n",
    "    # calculate output\n",
    "    output = neuron.predict(train_data[:,neuron.x1_index],train_data[:,neuron.x2_index])\n",
    "    best_neurons_output.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = np.array(list(zip(*best_neurons_output))) \n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the RBF function\n",
    "def radial_basis_function(x, c, sigma):\n",
    "    return np.exp(-0.5 * np.linalg.norm(x - c) ** 2 / (sigma ** 2))\n",
    "\n",
    "# Initialize parameters \n",
    "num_input_neurons = 2\n",
    "num_rbf_neurons = 12\n",
    "learning_rate = 0.15\n",
    "\n",
    "# Generate random initial values for weights, cluster centers, and standard deviations\n",
    "np.random.seed(42)\n",
    "w =  2 * np.random.rand(num_rbf_neurons) - 1\n",
    "centers = np.random.rand(num_rbf_neurons, num_input_neurons)\n",
    "sigmas = np.random.rand(num_rbf_neurons)\n",
    "\n",
    "# Training data (example)\n",
    "X_train = inputs\n",
    "y_train = train_output\n",
    "\n",
    "epochs = 100  # Number of training iterations\n",
    "error_data_train = np.zeros(len(X_train))\n",
    "mse_train = np.zeros(epochs)\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_error = 0\n",
    "    output_data_train = np.zeros(len(X_train))\n",
    "    for i in range(len(X_train)): \n",
    "        # Forward pass\n",
    "        x = X_train[i]\n",
    "        rbfs_output = np.array([radial_basis_function(x, c, sigma) for c, sigma in zip(centers, sigmas)])\n",
    "        y = np.dot(rbfs_output, w)\n",
    "        output_data_train[i] = y\n",
    "        # Calculate error\n",
    "        error = y_train[i] - y\n",
    "        error_data_train[i] = error\n",
    "        total_error += 0.5 * (error ** 2)\n",
    "\n",
    "        # Backpropagation\n",
    "        for j in range(num_rbf_neurons):\n",
    "            # Update weights\n",
    "            delta_w = -error * rbfs_output[j]\n",
    "            w[j] -= learning_rate * delta_w\n",
    "\n",
    "            # Update cluster centers\n",
    "            delta_c = (error * w[j] * (x - centers[j])) / (sigmas[j] ** 2)\n",
    "            centers[j] -= learning_rate * delta_c\n",
    "\n",
    "            # Update standard deviations\n",
    "            delta_sigma = (error * w[j] * np.linalg.norm(x - centers[j]) ** 2) / (sigmas[j] ** 3)\n",
    "            sigmas[j] -= learning_rate * delta_sigma\n",
    "    mse_train[epoch] = np.mean(error_data_train ** 2)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Error = {total_error}\")\n",
    "    \n",
    "# # Plotting the training data and output\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(y_train[5:])\n",
    "    plt.plot(output_data_train[5:], 'r', linewidth=0.5)\n",
    "    plt.xlabel('Train Data')\n",
    "    plt.ylabel('Output')\n",
    "    plt.legend(['Actual', 'Predicted']) \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting the training MSE\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.semilogy(np.arange(1, epoch + 1), mse_train[:epoch])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Train') \n",
    "    \n",
    "    print('Epoch: {} \\t'.format(epoch+1))\n",
    "    print('total_error: ',total_error)\n",
    "    print('MSE_train: {:.4f}'.format(mse_train[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.01556572 -0.01568061\n",
    "total_error:  0.3582647650886961\n",
    "MSE_train: 0.0005"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP4cHBUTTRrxiRZtggpjKCM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
