{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798fb985",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e087d3",
   "metadata": {},
   "source": [
    "# Combine train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210cd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "def merge_csv_files(file1, file2, output_file):\n",
    "    # Read data from both CSV files\n",
    "    data1 = pd.read_csv(file1)\n",
    "    data2 = pd.read_csv(file2)\n",
    "    \n",
    "    # Concatenate the dataframes vertically\n",
    "    merged_data = pd.concat([data1, data2], ignore_index=True)\n",
    "    \n",
    "    # Move the first column to the last\n",
    "    columns = merged_data.columns.tolist()\n",
    "    columns = columns[1:] + [columns[0]]\n",
    "    data = merged_data[columns]\n",
    "    \n",
    "    # Write the merged data to a new Excel file\n",
    "    data.to_excel(output_file, index=False)\n",
    "\n",
    "merge_csv_files(\"./fashion-mnist_test.csv\", \"./fashion-mnist_train.csv\", \"./fashion-mnist.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e3006",
   "metadata": {},
   "source": [
    "# Generate client datasets(full-non-iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_excel(\"./fashion-mnist.xlsx\") \n",
    "\n",
    "# Define the number of classes and class labels\n",
    "num_classes = 10\n",
    "class_labels = np.arange(num_classes)\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "# Create a directory to store the Excel files for each node\n",
    "if not os.path.exists('./client-datasets/full-non-iid'):\n",
    "    os.makedirs('./client-datasets/full-non-iid')\n",
    "\n",
    "# Function to split the dataset into nodes and save to Excel\n",
    "def create_full_non_iid_dataset(class_label):\n",
    "    # Filter data belonging to the specified class\n",
    "    class_data = data[data['label'] == class_label]\n",
    "    \n",
    "    # Calculate the midpoint of the class data\n",
    "    midpoint = len(class_data) // 2\n",
    "    \n",
    "    # Take the first half of the data\n",
    "    class_data = class_data.iloc[:midpoint, :]\n",
    "    \n",
    "    # Save data to Excel\n",
    "    class_data.to_excel(f'./client-datasets/full-non-iid/client-{class_label+1}.xlsx', index=False)\n",
    "    \n",
    "    # Append data to the new_dataset list\n",
    "    new_dataset.append(class_data)\n",
    "\n",
    "# Iterate over each class and create a dataset for each node\n",
    "for class_label in class_labels:\n",
    "    create_full_non_iid_dataset(class_label)\n",
    "\n",
    "# Concatenate dataframes in new_dataset into a single dataframe\n",
    "new_dataset_combined = pd.concat(new_dataset, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to Excel\n",
    "new_dataset_combined.to_excel(f'./fashion-mnist-new.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ba753",
   "metadata": {},
   "source": [
    "# Generate client datasets(99%-non-iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_excel(\"./fashion-mnist-new.xlsx\") \n",
    "\n",
    "# Define the number of classes and class labels\n",
    "num_classes = 10\n",
    "class_labels = np.arange(num_classes)\n",
    "\n",
    "# Create a directory to store the Excel files for each node \n",
    "if not os.path.exists('./client-datasets/99-non-iid'):\n",
    "    os.makedirs('./client-datasets/99-non-iid')\n",
    "\n",
    "# Function to split the dataset into nodes and save to Excel\n",
    "def create_99_non_iid_datasets():\n",
    "    # Shuffle the data\n",
    "    data_shuffled = data.sample(frac=1, random_state=42)\n",
    "    \n",
    "    # Initialize a dictionary to store data for each node\n",
    "    node_data = {label: pd.DataFrame(columns=data.columns) for label in class_labels}\n",
    "    \n",
    "    # Assign 99% of data to different classes\n",
    "    for label in class_labels:\n",
    "        class_data = data_shuffled[data_shuffled['label'] == label]\n",
    "        node_data[label] = class_data.iloc[:int(0.99 * len(class_data)), :]\n",
    "    \n",
    "    # Distribute the remaining 1% evenly among all nodes\n",
    "    remaining_data = data_shuffled.iloc[int(0.99 * len(data_shuffled)):, :]\n",
    "    remaining_data_indices = remaining_data.index.tolist()\n",
    "    random.shuffle(remaining_data_indices)\n",
    "    \n",
    "    for i, idx in enumerate(remaining_data_indices):\n",
    "        node_label = class_labels[i % num_classes]\n",
    "        node_data[node_label] = node_data[node_label].append(data_shuffled.loc[idx])\n",
    "    \n",
    "    # Save data to CSV for each node\n",
    "    for label, node_df in node_data.items():\n",
    "        \n",
    "        node_df.to_excel(f'./client-datasets/99-non-iid/client-{label+1}.xlsx', index=False)\n",
    "\n",
    "# Call the function to create node datasets\n",
    "create_99_non_iid_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
