{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0962c515",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112c70b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('classification-iris.xlsx', header=None).values\n",
    "# data = pd.read_excel('classification-seeds.xlsx', header=None).values\n",
    "\n",
    "# Shuffle the data\n",
    "data = shuffle(data, random_state=42)\n",
    "\n",
    "\n",
    "num_data = data.shape[0]\n",
    "num_col = data.shape[1]\n",
    "num_class = len(np.unique(data[:,num_col-1]))\n",
    "\n",
    "# Normalize the input data\n",
    "for ii in range(num_col - 1):\n",
    "    data[:, ii] = data[:, ii] / np.max(data[:, ii])\n",
    "\n",
    "# split data\n",
    "percent_train = 0.7\n",
    "num_train = round(num_data * percent_train)\n",
    "num_test = num_data - num_train\n",
    "\n",
    "\n",
    "# Convert labels to one-hot encoding (necessary for multi-class classification) \n",
    "y_one_hot_train = np.zeros((num_train, num_class))\n",
    "y_one_hot_train[np.arange(num_train), data[:num_train, num_col-1].astype(int)-1] = 1 \n",
    "\n",
    "y_one_hot_test = np.zeros((num_test, num_class))\n",
    "y_one_hot_test[np.arange(num_test), data[num_train:, num_col-1].astype(int)-1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f6ccc",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d77c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iris\n",
    "n0 = data.shape[1]-1\n",
    "n1 = 10\n",
    "n2 = 7\n",
    "n3 = 3\n",
    "n4 = num_class\n",
    "\n",
    "# # iris\n",
    "eta = 0.001\n",
    "epoch = 500\n",
    "\n",
    "# # seed\n",
    "# n0 = data.shape[1]-1\n",
    "# n1 = 8\n",
    "# n2 = 15\n",
    "# n3 = 5\n",
    "# n4 = num_class\n",
    "\n",
    "# # seed\n",
    "# eta = 0.01\n",
    "# epoch = 60\n",
    "\n",
    "mse_train = np.zeros((epoch,num_class))\n",
    "mse_test = np.zeros((epoch,num_class)) \n",
    "output_data_train = np.zeros(epoch)\n",
    "output_data_test = np.zeros(epoch)\n",
    "\n",
    "a = -1\n",
    "b = 1\n",
    "\n",
    "# Initialize weights\n",
    "np.random.seed(1)\n",
    "w1 = np.random.uniform(a, b, size=(n1, n0))\n",
    "w2 = np.random.uniform(a, b, size=(n2, n1))\n",
    "w3 = np.random.uniform(a, b, size=(n3, n2))\n",
    "w4 = np.random.uniform(a, b, size=(n4, n3))\n",
    "\n",
    "# Initialize biases\n",
    "bias1 = np.random.uniform(a, b, size=(n1, 1))\n",
    "bias2 = np.random.uniform(a, b, size=(n2, 1))\n",
    "bias3 = np.random.uniform(a, b, size=(n3, 1))\n",
    "bias4 = np.random.uniform(a, b, size=(n4, 1))\n",
    "\n",
    "CorrectiveMatrix = np.ones((num_class,1))\n",
    "\n",
    "w_par = np.zeros((num_train,n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1 + n3 * n2 + n3 * 1 + n4 * n3 + n4 * 1))\n",
    "I = np.eye(n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1 + n3 * n2 + n3 * 1 + n4 * n3 + n4 * 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c09d95",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df97a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in range(epoch):\n",
    "    total_error = 0 \n",
    "    error = np.zeros((num_train, num_class)) \n",
    "    \n",
    "    for i in range(num_train):\n",
    "        # feed-forward\n",
    "        input_data = data[i, :num_col-1].reshape(-1,1) \n",
    "        net1 = w1 @ input_data + bias1\n",
    "        o1 = 2/(1 + np.exp(-net1 ** 2))-1 \n",
    "        net2 = w2 @ o1 + bias2\n",
    "        o2 = 2 / (1 + np.exp(-net2 ** 2)) -1\n",
    "        net3 = w3 @ o2 + bias3\n",
    "        o3 = 2 / (1 + np.exp(-net3 ** 2)) - 1\n",
    "        net4 = w4 @ o3 + bias4\n",
    "        o4 =  1 / (1 + np.exp(-net4))  \n",
    "        \n",
    "        # Backpropagation for a single sample\n",
    "        error[i] = (y_one_hot_train[i:i+1]).flatten() - o4.flatten()\n",
    "\n",
    "        t1 = (1 - o1**2).reshape(-1,1)\n",
    "        A = np.diag(t1.flatten())\n",
    "\n",
    "        t2 = (1 - o2**2).reshape(-1,1)\n",
    "        B = np.diag(t2.flatten())\n",
    "        \n",
    "        t3 = (1-o3 ** 2).reshape(-1,1)\n",
    "        C = np.diag(t3.flatten())\n",
    "        \n",
    "        t4 = o4*(1-o4).reshape(-1,1)\n",
    "        D =np.diag(t4.flatten())\n",
    "                \n",
    "        #pw1 = -1  *(o4(1-o4)) * w4*(1-o3**2) * w3 *(1-o2**2) * w2 *(1-o1 **2) * input\n",
    "        #pw1 = -1 * ((w4.T @ D).T @ C @ w3 @ B @ w2 @ A).T @ input_data\n",
    "        #CorrectiveMatrix = np.array([[1], [1], [1]])\n",
    "        pw1 = -1 * (((w4.T @ D).T @ C @ w3 @ B @ w2 @ A).T @ CorrectiveMatrix) @ input_data.T  \n",
    "        pb1 = -1 * (((w4.T @ D).T @ C @ w3 @ B @ w2 @ A).T @ CorrectiveMatrix)\n",
    "        \n",
    "        # -1 * F’(net4) * w4 * F’(net3)* w3 * F’(net2) * o1 =-1 * *(o4(1-o4)) * w4*(1-o3**2) * w3 *(1-o2**2) * o1\n",
    "        pw2 = -1 * (((w4.T @ D).T  @ C @ w3 @ B).T @ CorrectiveMatrix  @ o1.T)\n",
    "        pb2 = -1 * (((w4.T @ D).T  @ C @ w3 @ B).T @ CorrectiveMatrix)\n",
    "    \n",
    "        # -1*(o4(1-o4)) * w4*(1-o3**2) *o2\n",
    "        pw3 = -1 * ((w4.T @ D).T @  C).T  @ CorrectiveMatrix @ o2.T\n",
    "        pb3 = -1 * ((w4.T @ D).T @  C).T  @ CorrectiveMatrix \n",
    "        \n",
    "        #-1 * F’(net4) * o3 =  -1* o4(1-o4) * o3 \n",
    "        pw4 = -1 *  (D @ CorrectiveMatrix @ o3.T)\n",
    "        pb4 = -1 *  (D @ CorrectiveMatrix)\n",
    "                \n",
    "        a = pw1.flatten()\n",
    "        b = pb1.flatten()\n",
    "        c = pw2.flatten()\n",
    "        d = pb2.flatten()\n",
    "        e = pw3.flatten()\n",
    "        f = pb3.flatten()\n",
    "        g = pw4.flatten()\n",
    "        h = pb4.flatten()\n",
    "        \n",
    "        w_par[i, :] = np.concatenate((a, b, c, d, e, f, g, h))\n",
    "                \n",
    "        total_error += np.abs(error[i]) \n",
    "\n",
    "    a1 = w1.reshape(-1,1)\n",
    "    b1 = bias1.reshape(-1,1)\n",
    "    c1 = w2.reshape(-1,1)\n",
    "    d1 = bias2.reshape(-1,1)\n",
    "    e1 = w3.reshape(-1,1)\n",
    "    f1 = bias3.reshape(-1,1)\n",
    "    g1 = w4.reshape(-1,1)\n",
    "    h1 = bias4.reshape(-1,1)\n",
    "\n",
    "    w_par1 = np.concatenate((a1, b1, c1, d1, e1, f1, g1, h1)).reshape(-1,1)\n",
    "\n",
    "    miu = (error.T @ error).flatten()[0]\n",
    " \n",
    "    w_par1 = w_par1 - np.linalg.inv((w_par.T @ w_par) + miu * I) @ w_par.T @ (error @ CorrectiveMatrix)\n",
    "    \n",
    "    a2 = w_par1[:n1 * n0].reshape((n1, n0))\n",
    "    b2 = w_par1[n1 * n0:n1 * n0 + n1 * 1].reshape((n1,1))\n",
    "    c2 = w_par1[n1 * n0 + n1 * 1: n1 * n0 + n1 * 1 + n2 * n1].reshape((n2, n1))\n",
    "    d2 =  w_par1[ n1 * n0 + n1 * 1 + n2 * n1: n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1].reshape((n2, 1))\n",
    "    e2 =  w_par1[ n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1: n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1 + n3 * n2].reshape((n3, n2))\n",
    "    f2 =  w_par1[ n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1 + n3 * n2: n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1 + n3 * n2 + n3 * 1].reshape((n3, 1))\n",
    "    g2 =  w_par1[ n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1 + n3 * n2 + n3 * 1: n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1 + n3 * n2 + n3 * 1 + n4 * n3].reshape((n4, n3))\n",
    "    h2 =  w_par1[ n1 * n0 + n1 * 1 + n2 * n1 + n2 * 1 + n3 * n2 + n3 * 1 + n4 * n3:].reshape((n4, 1))\n",
    "\n",
    "    w1 = a2\n",
    "    bias1 = b2\n",
    "    w2 = c2\n",
    "    bias2 = d2\n",
    "    w3 = e2\n",
    "    bias3 = f2\n",
    "    w4 = g2\n",
    "    bias4 = h2\n",
    "\n",
    "    error_data_train = np.zeros((num_train, num_class))\n",
    "    output_data_train = np.zeros(num_train)\n",
    "  \n",
    "    for i in range(num_train):\n",
    "        input_data = data[i, :num_col-1]\n",
    "        input_data = input_data.reshape(-1,1)\n",
    "        net1 = w1 @ input_data #(30, 4)x(4,1) = 30 x 1\n",
    "        \n",
    "        o1 = 2/(1 + np.exp(-net1 ** 2))-1 \n",
    "        net2 = w2 @ o1\n",
    "        o2 = 2 / (1 + np.exp(-net2 ** 2)) -1\n",
    "        net3 = w3 @ o2\n",
    "        o3 = 2 / (1 + np.exp(-net3 ** 2)) - 1\n",
    "        net4 = w4 @ o3\n",
    "        o4 =  1 / (1 + np.exp(-net4))\n",
    "#         o4 = net4\n",
    "\n",
    "        output_data_train[i] = np.argmax(o4)+1 \n",
    "        error_data_train[i] = (y_one_hot_train[i]).flatten() - o4.flatten()\n",
    "\n",
    "    mse_train[t] = np.mean(error_data_train ** 2,axis=0)\n",
    "\n",
    "    error_data_test = np.zeros((num_test, num_class))\n",
    "    output_data_test = np.zeros(num_test)\n",
    "    \n",
    "    \n",
    "    for i in range(num_test):\n",
    "        input_data = (data[num_train + i, :num_col-1]).reshape(-1,1) \n",
    "        net1 = w1 @ input_data  \n",
    "        o1 = 2/(1 + np.exp(-net1 ** 2))-1 \n",
    "        net2 = w2 @ o1\n",
    "        o2 = 2 / (1 + np.exp(-net2 ** 2)) -1\n",
    "        net3 = w3 @ o2\n",
    "        o3 = 2 / (1 + np.exp(-net3 ** 2)) - 1\n",
    "        net4 = w4 @ o3\n",
    "        o4 =  1 / (1 + np.exp(-net4))\n",
    "#         o4 = net4\n",
    "\n",
    "        output_data_test[i] = np.argmax(o4)+1\n",
    "    \n",
    "        error_data_test[i] = (y_one_hot_test[i:i+1]).flatten() - o4.flatten()\n",
    "\n",
    "    mse_test[t] = np.mean(error_data_test ** 2,axis=0)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(data[:num_train, num_col-1], '-sr')\n",
    "    plt.plot(output_data_train, '-*b')\n",
    "    plt.xlabel('Train Data')\n",
    "    plt.ylabel('Output')   \n",
    "    \n",
    "#         Plotting the training MSE\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.semilogy(np.arange(1, t + 1), mse_train[:t])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Train')\n",
    "    \n",
    "\n",
    "    plt.subplot(2, 2, 3)    \n",
    "    plt.plot(data[num_train:, num_col-1], '-sr')\n",
    "    plt.plot(output_data_test, '-*b')\n",
    "    plt.xlabel('Test Data')\n",
    "    plt.ylabel('Output')\n",
    "    \n",
    "        # Plotting the test MSE\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.semilogy(np.arange(1, t + 1), mse_test[:t])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Test')\n",
    "\n",
    "    \n",
    "    print('Epoch: {} \\t'.format(t+1))\n",
    "    print('MSE_train: ',mse_train[t],' MSE_Test: ' ,mse_test[t])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\\033[1;m\" + \"*\" * 125)\n",
    "    \n",
    "    \n",
    "plt.figure(2)\n",
    "m_train , b_train = np.polyfit(data[:num_train, num_col - 1], output_data_train, 1)    \n",
    "plt.scatter(data[:num_train, num_col - 1], output_data_train,facecolors='none',edgecolors='#104E8B')\n",
    "plt.plot(data[:num_train, num_col - 1], m_train*data[:num_train, num_col - 1]+b_train,'r')\n",
    "# plt.plot(data[:num_train, 3], output_data_train, label='Regression Line', color='red')\n",
    "plt.title('Regression Train') \n",
    "\n",
    "plt.figure(3)\n",
    "m_test , b_test = np.polyfit(data[num_train:, num_col - 1], output_data_test, 1)  \n",
    "plt.scatter(data[num_train:, num_col - 1], output_data_test,facecolors='none',edgecolors='#104E8B')\n",
    "plt.plot(data[num_train:, num_col - 1], m_test*data[num_train:,num_col - 1]+b_test,'r')\n",
    "plt.title('Regression Test')\n",
    " \n",
    "mse_train_result = mse_train[-1]\n",
    "mse_test_result = mse_test[-1]\n",
    "\n",
    "print(\"Final MSE on Train Data:\", mse_train_result)\n",
    "print(\"Final MSE on Test Data:\", mse_test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ede1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have converted regression predictions to classes\n",
    "predicted_classes = output_data_train \n",
    "actual_classes = data[:num_train,num_col-1] \n",
    "\n",
    "# Define the number of classes\n",
    "\n",
    "# Create a confusion matrix-like matrix\n",
    "confusion_matrix = np.zeros((num_class, num_class))\n",
    "\n",
    "# Fill the confusion matrix\n",
    "for actual, predicted in zip(actual_classes, predicted_classes):\n",
    "    confusion_matrix[actual.astype(int)-1][predicted.astype(int)-1] += 1\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Train Confusion Matrix ')\n",
    "plt.colorbar()\n",
    "\n",
    "# Annotate the plot with numbers\n",
    "for i in range(num_class):\n",
    "    for j in range(num_class):\n",
    "        plt.text(j, i, str(int(confusion_matrix[i, j])), fontsize=12, ha='center', va='center')  # Corrected\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(np.arange(num_class), np.arange(1, num_class + 1))\n",
    "plt.yticks(np.arange(num_class), np.arange(1, num_class + 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f788bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assuming you have converted regression predictions to classes\n",
    "predicted_classes = output_data_test \n",
    "actual_classes = data[num_train:,num_col-1] \n",
    "\n",
    "# Define the number of classes\n",
    "\n",
    "# Create a confusion matrix-like matrix\n",
    "confusion_matrix = np.zeros((num_class, num_class))\n",
    "\n",
    "# Fill the confusion matrix\n",
    "for actual, predicted in zip(actual_classes, predicted_classes):\n",
    "    confusion_matrix[actual.astype(int)-1][predicted.astype(int)-1] += 1\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Test Confusion Matrix ')\n",
    "plt.colorbar()\n",
    "\n",
    "# Annotate the plot with numbers\n",
    "for i in range(num_class):\n",
    "    for j in range(num_class):\n",
    "        plt.text(j, i, str(int(confusion_matrix[i, j])), fontsize=12, ha='center', va='center')  # Corrected\n",
    "# Adjust ticks and labels to start from 1\n",
    "        \n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "# plt.xticks(np.arange(num_class))\n",
    "# plt.yticks(np.arange(num_class))\n",
    "plt.xticks(np.arange(num_class), np.arange(1, num_class + 1))\n",
    "plt.yticks(np.arange(num_class), np.arange(1, num_class + 1))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708cbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = np.mean(output_data_train == data[:num_train,num_col-1] ) \n",
    "print(f\"Accuracy on the train set: {train_accuracy * 100}%\")\n",
    "\n",
    "test_accuracy = np.mean(output_data_test == data[num_train:,num_col-1]) \n",
    "print(f\"Accuracy on the test set: {test_accuracy * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
